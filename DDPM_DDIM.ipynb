{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ymleegit/Diffusion_Assignment1/blob/main/DDPM_DDIM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoZc8dtOF4M2"
      },
      "source": [
        "\n",
        "# <center> DDPM and DDIM\n",
        "\n",
        "<div align=center>\n",
        "\n",
        "[KAIST CS492(C): Diffusion and Flow Models (Fall 2025)](https://mhsung.github.io/kaist-cs492c-fall-2025/)\n",
        "\n",
        "Programming Assignment 1: DDPM and DDIM\n",
        "\n",
        "Instructor: [Minhyuk Sung](https://mhsung.github.io) (mhsung [at] kaist.ac.kr)\n",
        "\n",
        "TA: [Yunhong Min](https://myh4832.github.io/) (dbsghd363 [at] kaist.ac.kr)\n",
        "\n",
        "Credit: [Juil Koo](https://63days.github.io) (63days [at] kaist.ac.kr) & [Nguyen Minh Hieu](https://hieuristics.xyz/) (hieu1052k3 [at] gmail.com)\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1O85toQTt3DjIeQZ8aHXPydc5AsganCDJ\"></img>\n",
        "</div>\n",
        "\n",
        "## Abstract\n",
        "In this programming assignment, you will implement two representative diffusion-based generative models: the **Denoising Diffusion Probabilistic Model (DDPM)** and the **Denoising Diffusion Implicit Model (DDIM)**. Using a simple 2D toy dataset, you will train a noise prediction network and investigate both the forward and reverse processes of these models. The goal of this assignment is to gain hands-on experience in building diffusion models and to understand how DDPM and DDIM can exhibit different sampling behaviors, even when sharing the same noise prediction network.\n",
        "\n",
        "Before you start the assignment, we encourage you to review the following material for better understanding of the background of diffusion models:\n",
        "\n",
        "1. [[Paper](https://arxiv.org/abs/2006.11239)] Denoising Diffusion Probabilistic Models\n",
        "2. [[Paper](https://arxiv.org/abs/2010.02502)] Denoising Diffusion Implicit Models\n",
        "3. [[Blog](https://lilianweng.github.io/posts/2021-07-11-diffusion-models/)] Lilian Wang's \"What are Diffusion Models?\"\n",
        "\n",
        "<center>\n",
        "\n",
        "**Detailed submission guidelines and grading criteria are provided at the end of this Jupyter notebook.**\n",
        "\n",
        "</center>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vd5kpnXMOHqE"
      },
      "source": [
        "## Quick Summary of DDPM and DDIM\n",
        "\n",
        "<center>\n",
        "You can skip this summary and go directly to the implementation part below if you are already familiar with these models.\n",
        "</center>\n",
        "\n",
        "### Forward Process\n",
        "Denoising Diffusion Probabilistic Model (DDPM) is one of latent variable generative models consisting of a Markov chain. In the Markov chain, let us define a _forward process_ that gradually adds noise to the data sampled from a data distribution $\\mathbf{x}_0 \\sim q(\\mathbf{x}_0)$ so that $\\mathbf{x}_0$ becomes pure white Gaussian noise at $t=T$. Each transition of the forward process is as follows:\n",
        "\n",
        "$$ q(\\mathbf{x}_t | \\mathbf{x}_{t-1} := N(\\mathbf{x}_t; \\sqrt{1 - \\beta_t} \\mathbf{x}_{t-1}, \\beta_t \\mathbf{I})$$\n",
        "\n",
        "where a variance schedule $\\beta_1, \\dots, \\beta_T$ controlls the step sizes.\n",
        "\n",
        "Thanks to a nice property of Gaussians, we can directly sample $\\mathbf{x}_t$ at an arbitary timestep $t$ from real data $\\mathbf{x}_0$ in a closed form:\n",
        "\n",
        "$$ q(\\mathbf{x}_t | \\mathbf{x}_0) = N (\\mathbf{x}_t; \\sqrt{\\bar{\\alpha}_t} \\mathbf{x}_0, (1 - \\bar{\\alpha}_t) \\mathbf{I}), $$\n",
        "\n",
        "where $\\alpha_t := 1 - \\beta_t$ and $\\bar{\\alpha}_t := \\Pi_{s=1}^T \\alpha_s$.\n",
        "\n",
        "### Reverse Process\n",
        "If we can reverse the forward process, i.e. sample $\\mathbf{x}_{t-1} \\sim q(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ iteratively until $t=0$, we will be able to generate $\\mathbf{x}_0$ which is close to the unknown data distribution $\\mathbf{q}(\\mathbf{x}_0)$ from white Gaussian noise $\\mathbf{x}_T \\sim N(0, \\mathbf{I})$. You can think of this _reverse process_ as denoising process that gradually denoises noise so that it looks like a true sample from $q(\\mathbf{x}_0)$ at the end.\n",
        "The reverse process is also a Markov chain with learned Gaussian transitions:\n",
        "\n",
        "$$p_\\theta(\\mathbf{x}_{0:T}) := p(\\mathbf{x}_T) \\prod_{t=1}^T p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t), $$\n",
        "\n",
        "where $p(\\mathbf{x}_T) = N(0, \\mathbf{I})$ and $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t) := {N}(\\mathbf{x}_{t-1}; \\mathbf{\\boldsymbol{\\mu}}_\\theta (\\mathbf{x}_t, t)\\boldsymbol{\\Sigma}_\\theta (\\mathbf{x}_t, t)).$\n",
        "\n",
        "### Training\n",
        "To learn this reverse process, we set an objective function that minimizes KL divergence between $p_\\theta(\\mathbf{x}_{t-1} | \\mathbf{x}_t)$ and $q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) = \\mathcal{N}(\\tilde{\\boldsymbol{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0), \\sigma_t^2 \\mathbf{I})$ which is also a Gaussian distribution when conditioned on $\\mathbf{x}_0$:\n",
        "\n",
        "$$L = \\mathbb{E}_q \\left[ \\sum_{t > 1} D\\_{\\text{KL}}( q(\\mathbf{x}_{t-1} | \\mathbf{x}_t, \\mathbf{x}_0) \\Vert p_\\theta ( \\mathbf{x}_{t-1} | \\mathbf{x}_t)) \\right].$$\n",
        "\n",
        "As a parameterization of DDPM, the authors set $\\boldsymbol{\\Sigma}_\\theta(\\mathbf{x}_t, t) = \\sigma_t^2 \\mathbf{I}$ to untrained time dependent constants. As a result, we can rewrite the objective function:\n",
        "\n",
        "$${L} = \\mathbb{E}_q \\left[ \\frac{1}{2\\sigma_t^2} \\Vert \\tilde{\\boldsymbol{\\mu}}_t(\\mathbf{x}_t, \\mathbf{x}_0) - \\boldsymbol{\\mu}_{\\theta}(\\mathbf{x}_t, t) \\Vert^2 \\right] + C $$\n",
        "\n",
        "The authors empirically found that predicting $\\epsilon$ noise injected to data by a noise prediction network $\\epsilon_\\theta$ is better than learning the mean function $\\boldsymbol{\\mu}\\_\\theta$.\n",
        "\n",
        "In short, the simplified objective function of DDPM is defined as follows:\n",
        "\n",
        "$$ {L}_{\\text{simple}} := \\mathbb{E}_{t,\\mathbf{x}_0,\\boldsymbol{\\epsilon}} [ \\Vert \\boldsymbol{\\epsilon} - \\boldsymbol{\\epsilon}_\\theta( \\mathbf{x}_t(\\mathbf{x}_0, t), t) \\Vert^2  ],$$\n",
        "\n",
        "where $\\mathbf{x}_t (\\mathbf{x}_0, t) = \\sqrt{\\bar{\\alpha}_t}\\mathbf{x}_0 + \\sqrt{1 - \\bar{\\alpha}_t} \\boldsymbol{\\epsilon}$ and $\\boldsymbol{\\epsilon} \\sim {N}(0, \\mathbf{I})$.\n",
        "\n",
        "Refer to [the original DDPM paper](https://arxiv.org/abs/2006.11239) for more details.\n",
        "\n",
        "### Sampling\n",
        "\n",
        "Once we train the noise prediction network $\\boldsymbol{\\epsilon}_\\theta$, we can run sampling by gradually denoising white Gaussian noise. The algorithm of the DDPM  sampling is shown below:\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=1JW0-f81xlRrVNT84ATwHelVofT0i1Aex\"></src>\n",
        "</center>\n",
        "\n",
        "### Speed-Up with DDIM Sampling\n",
        "\n",
        "By now, you might be familiar with the concept of DDPM, particularly how it generates samples by gradually removing noise from the data.\n",
        "\n",
        "One downside of DDPM is the need to go through around a thousand of denoising steps to fully denoise the data, which is time-consuming. Surprisingly, the sampling process of DDPM can be accelerated with a simple mathematical tweak, **without the need to retrain the model from scratch**.\n",
        "\n",
        "Recall that the algorithm for DDPM sampling is nothing but a sequence of noise predictions and denoising steps. To speed up sampling, we keep the pre-trained DDPM and only switch each step within the loop (line 4 in Algorithm 2) to the following:\n",
        "\n",
        "<center>\n",
        "<img src=\"https://drive.google.com/uc?id=12MJ1DYn6iGA_ZWxLAV_nOEJro6DJc_DY\"></src>\n",
        "</center>\n",
        "\n",
        "Note that the symbol $\\alpha_t$ in the DDIM paper corresponds to $\\bar{\\alpha}_t$ in the DDPM paper."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMBt0oA3El8w"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-_YfRvD8K0D-"
      },
      "source": [
        "Before getting started, go to `Runtime` → `Change runtime type` on the top menu bar, and choose **T4 GPU** under Hardware Accelerator.\n",
        "\n",
        "You should then see `True` and the GPU status with the commands below:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4bbwoWhlEOMd",
        "outputId": "abba7d1a-2e90-4312-9eaf-c5e6af410df6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "Fri Feb 27 06:13:25 2026       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 580.82.07              Driver Version: 580.82.07      CUDA Version: 13.0     |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   38C    P8             13W /   70W |       3MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "\n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI              PID   Type   Process name                        GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(torch.cuda.is_available())\n",
        "!nvidia-smi"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Wpj-l_qEyKv"
      },
      "source": [
        "## Import Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cSi-g8D1DrIj"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "import math\n",
        "from ipywidgets import interact, IntSlider, Output\n",
        "from IPython.display import display, clear_output\n",
        "from PIL import Image\n",
        "from typing import List, Optional\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.spatial import KDTree\n",
        "from scipy.spatial.distance import cdist\n",
        "from sklearn import datasets\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from tqdm import tqdm\n",
        "SEED = 1234         # WARNING: DO NOT CHANGE THE SEED"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVyuQ3PkE-ov"
      },
      "source": [
        "## Dataset and Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aoh98mqZD97u"
      },
      "outputs": [],
      "source": [
        "def seed_everything(seed):\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "\n",
        "def normalize(ds, scaling_factor=2.0):\n",
        "    return (ds - ds.mean()) / ds.std() * scaling_factor\n",
        "\n",
        "\n",
        "def chamfer_distance(S1, S2) -> float:\n",
        "    r\"\"\"\n",
        "    Computes the Chamfer distance between two point clouds defined as:\n",
        "    d_CD(S1, S2) = \\sigma_{x \\in S1} min_{y in S2} ||x - y||^2 + \\sigma_{y \\in S2} min_{x in S1} ||x - y||^2\n",
        "    \"\"\"\n",
        "    dist = cdist(S1, S2)\n",
        "    dist1 = dist.min(axis=1) ** 2\n",
        "    dist2 = dist.min(axis=0) ** 2\n",
        "    return dist1.sum() + dist2.sum()\n",
        "\n",
        "\n",
        "def sample_checkerboard(n):\n",
        "    # https://github.com/ghliu/SB-FBSDE/blob/main/data.py\n",
        "    n_points = 3 * n\n",
        "    n_classes = 2\n",
        "    freq = 5\n",
        "    x = np.random.uniform(\n",
        "        -(freq // 2) * np.pi, (freq // 2) * np.pi, size=(n_points, n_classes)\n",
        "    )\n",
        "    mask = np.logical_or(\n",
        "        np.logical_and(np.sin(x[:, 0]) > 0.0, np.sin(x[:, 1]) > 0.0),\n",
        "        np.logical_and(np.sin(x[:, 0]) < 0.0, np.sin(x[:, 1]) < 0.0),\n",
        "    )\n",
        "    y = np.eye(n_classes)[1 * mask]\n",
        "    x0 = x[:, 0] * y[:, 0]\n",
        "    x1 = x[:, 1] * y[:, 0]\n",
        "    sample = np.concatenate([x0[..., None], x1[..., None]], axis=-1)\n",
        "    sqr = np.sum(np.square(sample), axis=-1)\n",
        "    idxs = np.where(sqr == 0)\n",
        "    sample = np.delete(sample, idxs, axis=0)\n",
        "\n",
        "    return sample\n",
        "\n",
        "\n",
        "def load_twodim(num_samples: int, dataset: str, dimension: int = 2):\n",
        "\n",
        "    if dataset == \"gaussian_centered\":\n",
        "        sample = np.random.normal(size=(num_samples, dimension))\n",
        "        sample = sample\n",
        "\n",
        "    if dataset == \"gaussian_shift\":\n",
        "        sample = np.random.normal(size=(num_samples, dimension))\n",
        "        sample = sample + 1.5\n",
        "\n",
        "    if dataset == \"circle\":\n",
        "        X, y = datasets.make_circles(\n",
        "            n_samples=num_samples, noise=0.0, random_state=None, factor=0.5\n",
        "        )\n",
        "        sample = X * 4\n",
        "\n",
        "    if dataset == \"scurve\":\n",
        "        X, y = datasets.make_s_curve(\n",
        "            n_samples=num_samples, noise=0.0, random_state=None\n",
        "        )\n",
        "        sample = normalize(X[:, [0, 2]])\n",
        "\n",
        "    if dataset == \"moon\":\n",
        "        X, y = datasets.make_moons(n_samples=num_samples, noise=0.0, random_state=None)\n",
        "        sample = normalize(X)\n",
        "\n",
        "    if dataset == \"swiss_roll\":\n",
        "        X, y = datasets.make_swiss_roll(\n",
        "            n_samples=num_samples, noise=0.0, random_state=None, hole=True\n",
        "        )\n",
        "        sample = normalize(X[:, [0, 2]])\n",
        "\n",
        "    if dataset == \"checkerboard\":\n",
        "        sample = normalize(sample_checkerboard(num_samples))\n",
        "\n",
        "    return torch.tensor(sample).float()\n",
        "\n",
        "\n",
        "class TwoDimDataClass(Dataset):\n",
        "    def __init__(self, dataset_type: str, N: int, batch_size: int, dimension=2):\n",
        "\n",
        "        self.X = load_twodim(N, dataset_type, dimension=dimension)\n",
        "        self.name = dataset_type\n",
        "        self.batch_size = batch_size\n",
        "        self.dimension = 2\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.X[idx]\n",
        "\n",
        "    def get_dataloader(self, shuffle=True):\n",
        "        return DataLoader(\n",
        "            self,\n",
        "            batch_size=self.batch_size,\n",
        "            shuffle=shuffle,\n",
        "            pin_memory=True,\n",
        "        )\n",
        "\n",
        "\n",
        "def get_data_iterator(iterable):\n",
        "    iterator = iterable.__iter__()\n",
        "    while True:\n",
        "        try:\n",
        "            yield iterator.__next__()\n",
        "        except StopIteration:\n",
        "            iterator = iterable.__iter__()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qbvWNaRwFGPB"
      },
      "source": [
        "## Visualize target and prior distributions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zl6jHQzcFHvJ"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "seed_everything(SEED)\n",
        "\n",
        "target_ds = TwoDimDataClass(dataset_type='swiss_roll',\n",
        "                            N=1000000,\n",
        "                            batch_size=256)\n",
        "\n",
        "prior_ds = TwoDimDataClass(dataset_type='gaussian_centered',\n",
        "                           N=1000000,\n",
        "                           batch_size=256)\n",
        "\n",
        "num_vis_particles = 500\n",
        "sample_f = target_ds[0:num_vis_particles]\n",
        "sample_b = prior_ds[0:num_vis_particles]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_subplot(1, 1, 1)\n",
        "ax.scatter(sample_f[:, 0], sample_f[:, 1], alpha=0.6)\n",
        "ax.scatter(sample_b[:, 0], sample_b[:, 1], alpha=0.6)\n",
        "ax.grid(False)\n",
        "ax.set_aspect('equal', adjustable='box')\n",
        "strtitle = \"Target and prior distributions\"\n",
        "ax.set_title(strtitle)\n",
        "ax.legend(['Target', r'Prior (=$\\mathcal{N}(\\mathbf{0}, \\mathbf{I})$)'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sVXJ1mqMUAmV"
      },
      "source": [
        "## Task 1: DDPM with Swiss-Roll\n",
        "\n",
        "In this task, we will look into each component one by one in a toy experiment and implement them sequentally. After finishing the implementation, you will be able to train DDPM and evaluate the performance.\n",
        "\n",
        "❗️❗️❗️ **You are only allowed to edit the code enclosed with TODO comments. Do NOT modify any code outside these regions.** ❗️❗️❗️"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qAUD9rX8Mquc"
      },
      "source": [
        "## Task 1-1: Implement a Noise Prediction Neural Network\n",
        "\n",
        "Implement a noise prediction network based on the provided skeleton code. The network should consist of `TimeLinear` layers with feature dimensions following the sequence `[dim_in, dim_hids[0], ..., dim_hids[-1], dim_out]`. Each `TimeLinear` layer except for the last one must be followed by a ReLU activation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eNirEHccMrOC"
      },
      "outputs": [],
      "source": [
        "class TimeEmbedding(nn.Module):\n",
        "    def __init__(self, hidden_size, frequency_embedding_size=256):\n",
        "        super().__init__()\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(frequency_embedding_size, hidden_size, bias=True),\n",
        "            nn.SiLU(),\n",
        "            nn.Linear(hidden_size, hidden_size, bias=True),\n",
        "        )\n",
        "        self.frequency_embedding_size = frequency_embedding_size\n",
        "\n",
        "    @staticmethod\n",
        "    def timestep_embedding(t, dim, max_period=10000):\n",
        "        \"\"\"\n",
        "        Create sinusoidal timestep embeddings.\n",
        "        :param t: a 1-D Tensor of N indices, one per batch element.\n",
        "                          These may be fractional.\n",
        "        :param dim: the dimension of the output.\n",
        "        :param max_period: controls the minimum frequency of the embeddings.\n",
        "        :return: an (N, D) Tensor of positional embeddings.\n",
        "        \"\"\"\n",
        "        # https://github.com/openai/glide-text2im/blob/main/glide_text2im/nn.py\n",
        "        half = dim // 2\n",
        "        freqs = torch.exp(\n",
        "            -math.log(max_period)\n",
        "            * torch.arange(start=0, end=half, dtype=torch.float32)\n",
        "            / half\n",
        "        ).to(device=t.device)\n",
        "        args = t[:, None].float() * freqs[None]\n",
        "        embedding = torch.cat([torch.cos(args), torch.sin(args)], dim=-1)\n",
        "        if dim % 2:\n",
        "            embedding = torch.cat(\n",
        "                [embedding, torch.zeros_like(embedding[:, :1])], dim=-1\n",
        "            )\n",
        "        return embedding\n",
        "\n",
        "    def forward(self, t: torch.Tensor):\n",
        "        if t.ndim == 0:\n",
        "            t = t.unsqueeze(-1)\n",
        "        t_freq = self.timestep_embedding(t, self.frequency_embedding_size)\n",
        "        t_emb = self.mlp(t_freq)\n",
        "        return t_emb\n",
        "\n",
        "\n",
        "class TimeLinear(nn.Module):\n",
        "    def __init__(self, dim_in: int, dim_out: int, num_timesteps: int):\n",
        "        super().__init__()\n",
        "        self.dim_in = dim_in\n",
        "        self.dim_out = dim_out\n",
        "        self.num_timesteps = num_timesteps\n",
        "\n",
        "        self.time_embedding = TimeEmbedding(dim_out)\n",
        "        self.fc = nn.Linear(dim_in, dim_out)\n",
        "\n",
        "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
        "        x = self.fc(x)\n",
        "        alpha = self.time_embedding(t).view(-1, self.dim_out)\n",
        "\n",
        "        return alpha * x\n",
        "\n",
        "\n",
        "class SimpleNet(nn.Module):\n",
        "    def __init__(\n",
        "        self, dim_in: int, dim_out: int, dim_hids: List[int], num_timesteps: int\n",
        "    ):\n",
        "        super().__init__()\n",
        "        \"\"\"\n",
        "        (TODO) Build a noise estimating network.\n",
        "\n",
        "        Args:\n",
        "            dim_in: dimension of input\n",
        "            dim_out: dimension of output\n",
        "            dim_hids: dimensions of hidden features\n",
        "            num_timesteps: number of timesteps\n",
        "        \"\"\"\n",
        "\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        self.tlins = []\n",
        "\n",
        "        ######################\n",
        "\n",
        "    def forward(self, x: torch.Tensor, t: torch.Tensor):\n",
        "        \"\"\"\n",
        "        (TODO) Implement the forward pass. This should output\n",
        "        the noise prediction of the noisy input x at timestep t.\n",
        "\n",
        "        Args:\n",
        "            x: the noisy data after t period diffusion\n",
        "            t: the time that the forward diffusion has been running\n",
        "        \"\"\"\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        for i in range(len(self.tlins)):\n",
        "            pass\n",
        "\n",
        "        ######################\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SduU8Hf1SOL1"
      },
      "source": [
        "## Task 1-2: Complete a DDPM scheduler.\n",
        "\n",
        "Compute `alphas` and `alphas_cumprod`, which correspond to the sequences of $\\alpha_t:=1-\\beta_t$ and $\\bar{\\alpha}_t:=\\Pi_{s=1}^t \\alpha_s$, respectively (as defined in the DDPM paper)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrPOy9wVNTB6"
      },
      "outputs": [],
      "source": [
        "class BaseScheduler(nn.Module):\n",
        "    \"\"\"\n",
        "    Variance scheduler of DDPM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        num_train_timesteps: int,\n",
        "        beta_1: float = 1e-4,\n",
        "        beta_T: float = 0.02,\n",
        "        mode: str = \"linear\",\n",
        "    ):\n",
        "        super().__init__()\n",
        "        self.num_train_timesteps = num_train_timesteps\n",
        "        self.timesteps = torch.from_numpy(\n",
        "            np.arange(0, self.num_train_timesteps)[::-1].copy().astype(np.int64)\n",
        "        )\n",
        "\n",
        "        if mode == \"linear\":\n",
        "            betas = torch.linspace(beta_1, beta_T, steps=num_train_timesteps)\n",
        "        elif mode == \"quad\":\n",
        "            betas = (\n",
        "                torch.linspace(beta_1**0.5, beta_T**0.5, num_train_timesteps) ** 2\n",
        "            )\n",
        "        else:\n",
        "            raise NotImplementedError(f\"{mode} is not implemented.\")\n",
        "\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        # Compute alphas and alphas_cumprod.\n",
        "        alphas = None\n",
        "        alphas_cumprod = None\n",
        "\n",
        "        ######################\n",
        "\n",
        "        self.register_buffer(\"betas\", betas)\n",
        "        self.register_buffer(\"alphas\", alphas)\n",
        "        self.register_buffer(\"alphas_cumprod\", alphas_cumprod)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uH-XopBJWves"
      },
      "source": [
        "## Task 1-3: Complete the core functions of DDPM.\n",
        "\n",
        "Implement forward and reverse processes of DDPM inside the class below.\n",
        "\n",
        "- `q_sample()` is a forward pass that maps $\\mathbf{x}_0$ to $\\mathbf{x}_t$.  \n",
        "\n",
        "- `p_sample()` is a reverse transition from $\\mathbf{x}_t$ to $\\mathbf{x}_{t-1}$, and\n",
        "\n",
        "- `p_sample_loop()` is the full iterative reverse process, corresponding to the DDPM sampling algorithm.\n",
        "\n",
        "Finally, implement the training objective:\n",
        "- `comput_loss()` should be the simplified noise matching loss in the DDPM paper.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ByTtwIpFSeDH"
      },
      "outputs": [],
      "source": [
        "def extract(input, t: torch.Tensor, x: torch.Tensor):\n",
        "    if t.ndim == 0:\n",
        "        t = t.unsqueeze(0)\n",
        "    shape = x.shape\n",
        "    t = t.long().to(input.device)\n",
        "    out = torch.gather(input, 0, t)\n",
        "    reshape = [t.shape[0]] + [1] * (len(shape) - 1)\n",
        "    return out.reshape(*reshape)\n",
        "\n",
        "class DDPM(nn.Module):\n",
        "    \"\"\"\n",
        "    A high-level wrapper of DDPM.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, network: nn.Module, var_scheduler: BaseScheduler):\n",
        "        super().__init__()\n",
        "        self.network = network\n",
        "        self.var_scheduler = var_scheduler\n",
        "\n",
        "    @property\n",
        "    def device(self):\n",
        "        return next(self.network.parameters()).device\n",
        "\n",
        "    def q_sample(self, x0, t, noise=None):\n",
        "        \"\"\"\n",
        "        sample x_t from q(x_t | x_0) of DDPM.\n",
        "\n",
        "        Input:\n",
        "            x0 (`torch.Tensor`): clean data to be mapped to timestep t in the forward process of DDPM.\n",
        "            t (`torch.Tensor`): timestep\n",
        "            noise (`torch.Tensor`, optional): random Gaussian noise. if None, randomly sample Gaussian noise in the function.\n",
        "        Output:\n",
        "            xt (`torch.Tensor`): noisy samples\n",
        "        \"\"\"\n",
        "        if noise is None:\n",
        "            noise = torch.randn_like(x0)\n",
        "\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        # Compute xt.\n",
        "        alphas_prod_t = extract(self.var_scheduler.alphas_cumprod, t, x0)\n",
        "        xt = x0\n",
        "\n",
        "        #######################\n",
        "\n",
        "        return xt\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def p_sample(self, xt, t):\n",
        "        \"\"\"\n",
        "        One step denoising function of DDPM: x_t -> x_{t-1}.\n",
        "\n",
        "        Input:\n",
        "            xt (`torch.Tensor`): samples at arbitrary timestep t.\n",
        "            t (`torch.Tensor`): current timestep in a reverse process.\n",
        "        Ouptut:\n",
        "            x_t_prev (`torch.Tensor`): one step denoised sample. (= x_{t-1})\n",
        "\n",
        "        \"\"\"\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        # compute x_t_prev.\n",
        "        if isinstance(t, int):\n",
        "            t = torch.tensor([t]).to(self.device)\n",
        "        eps_factor = (1 - extract(self.var_scheduler.alphas, t, xt)) / (\n",
        "            1 - extract(self.var_scheduler.alphas_cumprod, t, xt)\n",
        "        ).sqrt()\n",
        "        eps_theta = self.network(xt, t)\n",
        "\n",
        "        x_t_prev = xt\n",
        "\n",
        "        #######################\n",
        "        return x_t_prev\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def p_sample_loop(self, shape):\n",
        "        \"\"\"\n",
        "        The loop of the reverse process of DDPM.\n",
        "\n",
        "        Input:\n",
        "            shape (`Tuple`): The shape of output. e.g., (num particles, 2)\n",
        "        Output:\n",
        "            x0_pred (`torch.Tensor`): The final denoised output through the DDPM reverse process.\n",
        "        \"\"\"\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        # sample x0 based on Algorithm 2 of DDPM paper.\n",
        "        x0_pred = torch.zeros(shape).to(self.device)\n",
        "\n",
        "        ######################\n",
        "        return x0_pred\n",
        "\n",
        "    def compute_loss(self, x0):\n",
        "        \"\"\"\n",
        "        The simplified noise matching loss corresponding Equation 14 in DDPM paper.\n",
        "\n",
        "        Input:\n",
        "            x0 (`torch.Tensor`): clean data\n",
        "        Output:\n",
        "            loss: the computed loss to be backpropagated.\n",
        "        \"\"\"\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        # compute noise matching loss.\n",
        "        batch_size = x0.shape[0]\n",
        "        t = (\n",
        "            torch.randint(0, self.var_scheduler.num_train_timesteps, size=(batch_size,))\n",
        "            .to(x0.device)\n",
        "            .long()\n",
        "        )\n",
        "\n",
        "        loss = x0.mean()\n",
        "\n",
        "        ######################\n",
        "        return loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkwU6_PDZJ-t"
      },
      "source": [
        "## Build a DDPM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J1m0ohHIY2Hy"
      },
      "outputs": [],
      "source": [
        "# hyperparameters #\n",
        "# Don't change it\n",
        "device = torch.device(\"cuda\")\n",
        "config = {\n",
        "    \"num_diffusion_steps\": 1000,\n",
        "    \"dim_hids\": [128, 128, 128],\n",
        "    \"lr\": 1e-3,\n",
        "    \"batch_size\": 128,\n",
        "    \"num_train_iters\": 5000,\n",
        "    \"device\": device,\n",
        "}\n",
        "###################\n",
        "\n",
        "def build_ddpm(config):\n",
        "    network = SimpleNet(dim_in=2,\n",
        "                        dim_out=2,\n",
        "                        dim_hids=config[\"dim_hids\"],\n",
        "                        num_timesteps=config[\"num_diffusion_steps\"]\n",
        "                       )\n",
        "    var_scheduler = BaseScheduler(config[\"num_diffusion_steps\"])\n",
        "\n",
        "    ddpm = DDPM(network, var_scheduler).to(config[\"device\"])\n",
        "    return ddpm\n",
        "\n",
        "ddpm = build_ddpm(config)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OYRAyEYQZM-v"
      },
      "source": [
        "## Visualize $q(\\mathbf{x}_t)$\n",
        "\n",
        "Once you finish the implementation so far, you should be able to see that the swiss-roll distribution on the leftmost gradually transforms into a Gaussian distribution as $t$ increases."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CebDMyntY9j2"
      },
      "outputs": [],
      "source": [
        "fig, axs = plt.subplots(1, 10, figsize=(28, 3))\n",
        "for i, t in enumerate(range(0, 500, 50)):\n",
        "    x_t = ddpm.q_sample(target_ds[:num_vis_particles].to(device), (torch.ones(num_vis_particles) * t).to(device))\n",
        "    x_t = x_t.cpu()\n",
        "    axs[i].scatter(x_t[:,0], x_t[:,1], color='white',edgecolor='gray', s=5)\n",
        "    axs[i].set_axis_off()\n",
        "    axs[i].set_title(r'$q(\\mathbf{x}_{'+str(t)+'})$')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CFcndwN5Z2Py"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MYNP5Jy8Z6dT"
      },
      "outputs": [],
      "source": [
        "def figure2image(fig):\n",
        "    buf = io.BytesIO()\n",
        "    fig.savefig(buf)\n",
        "    buf.seek(0)\n",
        "    img = Image.open(buf)\n",
        "    return img\n",
        "\n",
        "# Set seed\n",
        "seed_everything(SEED)\n",
        "\n",
        "# Initialize the model.\n",
        "ddpm = build_ddpm(config)\n",
        "\n",
        "pbar = tqdm(range(config[\"num_train_iters\"]))\n",
        "optimizer = torch.optim.Adam(ddpm.parameters(), lr=config[\"lr\"])\n",
        "train_dl = torch.utils.data.DataLoader(target_ds, batch_size=config[\"batch_size\"])\n",
        "train_iter = get_data_iterator(train_dl)\n",
        "\n",
        "losses = []\n",
        "images = []\n",
        "try:\n",
        "    for step in pbar:\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        batch_x = next(train_iter)\n",
        "        batch_x = batch_x.to(device)\n",
        "        loss = ddpm.compute_loss(batch_x)\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        pbar.set_description(f\"loss: {loss.item():.4f}\")\n",
        "\n",
        "        losses.append(loss.item())\n",
        "\n",
        "        if step % 199 == 0:\n",
        "            with torch.no_grad():\n",
        "                x0 = ddpm.p_sample_loop(shape=(num_vis_particles, 2)).cpu()\n",
        "\n",
        "                fig, ax = plt.subplots(1,1)\n",
        "                ax.scatter(x0[:,0], x0[:,1])\n",
        "                ax.set_title(f\"Samples at {step}-iteration\")\n",
        "                clear_output(wait=True)\n",
        "                plt.show()\n",
        "                img = figure2image(fig)\n",
        "                images.append(img)\n",
        "\n",
        "except KeyboardInterrupt:\n",
        "    pass\n",
        "finally:\n",
        "    if len(images) > 0:\n",
        "        slider = IntSlider(min=0, max=len(images)-1, step=1, value=1)\n",
        "        output = Output()\n",
        "        def display_image(index):\n",
        "            with output:\n",
        "                output.clear_output(wait=True)\n",
        "                display(images[index])\n",
        "        interact(display_image, index=slider)\n",
        "        display(output)\n",
        "        plt.plot(losses)\n",
        "        plt.title(\"Loss curve\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YPRHt1H3baK0"
      },
      "source": [
        "## Task 1 DDPM Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NW1pdc2eaQXG"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "seed_everything(SEED)\n",
        "\n",
        "num_eval_particles = 2048\n",
        "pc_ref = target_ds[:num_eval_particles]\n",
        "pc_gen = ddpm.p_sample_loop(shape=(num_eval_particles, 2))\n",
        "\n",
        "pc_gen = pc_gen.reshape(num_eval_particles, 2).cpu().numpy()\n",
        "pc_ref = pc_ref.reshape(num_eval_particles, 2).cpu().numpy()\n",
        "with torch.no_grad():\n",
        "    cd = chamfer_distance(\n",
        "        pc_gen,\n",
        "        pc_ref,\n",
        "    )\n",
        "    print(f\"DDPM Chamfer Distance: {cd.item():.4f}\")\n",
        "\n",
        "# Visualize samples with the target distribution.\n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.scatter(pc_ref[:,0], pc_ref[:,1], alpha=0.1, label=\"target distribution\")\n",
        "ax.scatter(pc_gen[:,0], pc_gen[:,1], alpha=0.1, label=\"samples\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6HxcE3mTcHZm"
      },
      "source": [
        "## Task 2: Implement a DDIM\n",
        "\n",
        "Now, we will complete the implementation of DDIM, which shares the same forward process with DDPM but use a different reverse process. After finishing the implementation, you will evaluate the DDIM sampling performance while using the same noise prediction network from the previous DDPM sampling.\n",
        "\n",
        "\n",
        "Complete `ddim_p_sample()` and `ddim_p_sample_loop()` functions in the DDIM class.\n",
        "\n",
        "❗️❗️❗️ **You are only allowed to edit the code enclosed with TODO comments. Do NOT modify any code outside these regions.** ❗️❗️❗️"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nt1yAQlabt2u"
      },
      "outputs": [],
      "source": [
        "class DDIM(DDPM):\n",
        "    \"\"\"\n",
        "    A high-level wrapper of DDIM.\n",
        "    \"\"\"\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def ddim_p_sample(self, xt, t, t_prev, eta=0.0):\n",
        "        \"\"\"\n",
        "        One step denoising function of DDIM: $x_t{\\tau_i}$ -> $x_{\\tau{i-1}}$.\n",
        "\n",
        "        Input:\n",
        "            xt (`torch.Tensor`): noisy data at timestep $\\tau_i$.\n",
        "            t (`torch.Tensor`): current timestep (=\\tau_i)\n",
        "            t_prev (`torch.Tensor`): next timestep in a reverse process (=\\tau_{i-1})\n",
        "            eta (float): correspond to η in DDIM which controls the stochasticity of a reverse process.\n",
        "        Output:\n",
        "           x_t_prev (`torch.Tensor`): one step denoised sample. (= $x_{\\tau_{i-1}}$)\n",
        "        \"\"\"\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        # Compute x_t_prev based on ddim reverse process, following Equation 12 of the DDIM paper.\n",
        "        alpha_prod_t = extract(self.var_scheduler.alphas_cumprod, t, xt)\n",
        "        if t_prev >= 0:\n",
        "            alpha_prod_t_prev = extract(self.var_scheduler.alphas_cumprod, t_prev, xt)\n",
        "        else:\n",
        "            alpha_prod_t_prev = torch.ones_like(alpha_prod_t)\n",
        "\n",
        "        x_t_prev = xt\n",
        "\n",
        "        ######################\n",
        "        return x_t_prev\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def ddim_p_sample_loop(self, shape, num_inference_timesteps=50, eta=0.0):\n",
        "        r\"\"\"\n",
        "        The loop of the reverse process of DDIM.\n",
        "\n",
        "        Input:\n",
        "            shape (`Tuple`): The shape of output. e.g., (num particles, 2)\n",
        "            num_inference_timesteps (`int`): the number of timesteps in the reverse process.\n",
        "            eta (`float`): correspond to η in DDIM which controls the stochasticity of a reverse process.\n",
        "        Output:\n",
        "            x0_pred (`torch.Tensor`): The final denoised output through the DDPM reverse process.\n",
        "        \"\"\"\n",
        "        ######## TODO ########\n",
        "        # DO NOT change the code outside this part.\n",
        "        step_ratio = self.var_scheduler.num_train_timesteps // num_inference_timesteps\n",
        "        timesteps = (\n",
        "            (np.arange(0, num_inference_timesteps) * step_ratio)\n",
        "            .round()[::-1]\n",
        "            .copy()\n",
        "            .astype(np.int64)\n",
        "        )\n",
        "        timesteps = torch.from_numpy(timesteps)\n",
        "        prev_timesteps = timesteps - step_ratio\n",
        "\n",
        "        xt = torch.zeros(shape).to(self.device)\n",
        "        for t, t_prev in zip(timesteps, prev_timesteps):\n",
        "            pass\n",
        "\n",
        "        x0_pred = xt\n",
        "\n",
        "        ######################\n",
        "\n",
        "        return x0_pred\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwssxygbckmT"
      },
      "source": [
        "## Task 2 DDIM Evaluation\n",
        "\n",
        "We will load the same pre-trained noise prediction network used in the previous DDPM sampling, and then sample data following the DDIM reverse process."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8aeDRbNGceR9"
      },
      "outputs": [],
      "source": [
        "# Set seed\n",
        "seed_everything(SEED)\n",
        "\n",
        "ddim = DDIM(ddpm.network, ddpm.var_scheduler).to(config[\"device\"])\n",
        "\n",
        "num_eval_particles = 2048\n",
        "pc_ref = target_ds[:num_eval_particles]\n",
        "pc_gen = ddim.ddim_p_sample_loop(shape=(num_eval_particles, 2))\n",
        "\n",
        "pc_gen = pc_gen.reshape(num_eval_particles, 2).cpu().numpy()\n",
        "pc_ref = pc_ref.reshape(num_eval_particles, 2).cpu().numpy()\n",
        "with torch.no_grad():\n",
        "    cd = chamfer_distance(\n",
        "        pc_gen,\n",
        "        pc_ref,\n",
        "    )\n",
        "    print(f\"DDIM Chamfer Distance: {cd.item():.4f}\")\n",
        "\n",
        "# Visualize samples with the target distribution.\n",
        "fig, ax = plt.subplots(1,1)\n",
        "ax.scatter(pc_ref[:,0], pc_ref[:,1], alpha=0.1, label=\"target distribution\")\n",
        "ax.scatter(pc_gen[:,0], pc_gen[:,1], alpha=0.1, label=\"samples\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01OK_wuY_GDD"
      },
      "source": [
        "## What to Submit\n",
        "\n",
        "<details>\n",
        "<summary><b>Submission Item List</b></summary>\n",
        "</br>\n",
        "\n",
        "- [ ] Jupyter notebook file\n",
        "\n",
        "**Task 1 (DDPM)**\n",
        "- [ ] Loss curve screenshot\n",
        "<img src=\"https://drive.google.com/uc?id=1UemwPik_2MbDgVURvdxC02MHkrFkn0Na\"></img>\n",
        "\n",
        "- [ ] Screenshot of Chamfer Distance result\n",
        "- [ ] Visualization of DDPM sampling\n",
        "<img src=\"https://drive.google.com/uc?id=1CR-YzIOYxMvYG7cmBJuWIY_00mFPejvP\"></img>\n",
        "\n",
        "\n",
        "\n",
        "**Task 2 (DDIM)**\n",
        "- [ ] Screenshot of Chamfer Distance result\n",
        "- [ ] Visualization of DDIM sampling\n",
        "\n",
        "<img src=\"https://drive.google.com/uc?id=1Atg5pri-0JihV0b7mk7b9r77T-2sxw95\"></img>\n",
        "</details>\n",
        "\n",
        "\n",
        "Submit a single ZIP file named `{NAME}_{STUDENT_ID}.zip` containing the two followings:\n",
        "\n",
        "1. Jupyter notebook file containing your code implementation.\n",
        "2. A single PDF document named `{NAME}_{STUDENT_ID}.pdf` that includes:\n",
        "    - Your name and student ID\n",
        "    - All results listed in the submission item list above (screenshots, metrics, visualizations, etc.)\n",
        "\n",
        "\n",
        "## Grading\n",
        "\n",
        "**You will receive a zero score if:**\n",
        "- **you do not submit,**\n",
        "- **your code is not reproducible, or**\n",
        "- **you modify any code outside of the section enclosed with `TODO` or use different hyperparameters that are supposed to be fixed as given.**\n",
        "\n",
        "**Plagiarism in any form will also result in a zero score and will be reported to the university.**\n",
        "\n",
        "**Your score will incur a 10% deduction for each missing item.**\n",
        "\n",
        "Otherwise, you will receive up to 20 points from this assignment that count toward your final grade.\n",
        "\n",
        "- Task 1\n",
        "  - 10 points: Achieve CD lower than **20** from DDPM sampling.\n",
        "  - 5 points: Achieve CD between **20** and **40** from DDPM sampling.\n",
        "  - 0 point: otherwise.\n",
        "- Task 2\n",
        "  - 10 points: Achieve CD lower than **40** from DDIM sampling.\n",
        "  - 5 points: Achieve CD between **40** and **80** from DDIM sampling.\n",
        "  - 0 point: otherwise.\n",
        "\n",
        "\n",
        "## Further Readings\n",
        "\n",
        "If you are interested in this topic, we encourage you to check out the further materials below.\n",
        "\n",
        "- [Diffusion Models Beat GANs on Image Synthesis](https://arxiv.org/abs/2105.05233)\n",
        "- [Score-Based Generative Modeling through Stochastic Differential Equations](https://arxiv.org/abs/2011.13456)\n",
        "- [Generative Modeling by Estimating Gradients of the Data Distribution](https://yang-song.net/blog/2021/score/)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}